{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7629cf36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\python312\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: pandas in c:\\python312\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: scikit-learn in c:\\python312\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: xgboost in c:\\users\\kiit\\appdata\\roaming\\python\\python312\\site-packages (3.0.0)\n",
      "Requirement already satisfied: matplotlib in c:\\python312\\lib\\site-packages (3.10.1)\n",
      "Requirement already satisfied: seaborn in c:\\users\\kiit\\appdata\\roaming\\python\\python312\\site-packages (0.13.2)\n",
      "Requirement already satisfied: plotly in c:\\users\\kiit\\appdata\\roaming\\python\\python312\\site-packages (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\python312\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\python312\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\python312\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\python312\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\python312\\lib\\site-packages (from matplotlib) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\python312\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\python312\\lib\\site-packages (from matplotlib) (11.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\python312\\lib\\site-packages (from matplotlib) (3.2.3)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\kiit\\appdata\\roaming\\python\\python312\\site-packages (from plotly) (1.32.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! python -m pip install --user numpy pandas scikit-learn xgboost matplotlib seaborn plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68531ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       numpy: ✓ Installed\n",
      "      pandas: ✓ Installed\n",
      "     sklearn: ✓ Installed\n",
      "     xgboost: ✓ Installed\n",
      "  matplotlib: ✓ Installed\n",
      "     seaborn: ✓ Installed\n",
      "      plotly: ✓ Installed\n"
     ]
    }
   ],
   "source": [
    "libs = ['numpy', 'pandas', 'sklearn', 'xgboost', 'matplotlib', 'seaborn', 'plotly']\n",
    "\n",
    "for lib in libs:\n",
    "    try:\n",
    "        __import__(lib)\n",
    "        print(f\"{lib:>12}: ✓ Installed\")\n",
    "    except ImportError:\n",
    "        print(f\"{lib:>12}: ✗ Missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5bd02bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 2.0.1\n",
      "pandas: 2.2.3\n",
      "scikit-learn: 1.6.1\n",
      "xgboost: 3.0.0\n",
      "matplotlib: 3.10.1\n",
      "seaborn: 0.13.2\n",
      "plotly: 6.0.1\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import xgboost\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "\n",
    "print(f\"numpy: {np.__version__}\")\n",
    "print(f\"pandas: {pd.__version__}\")\n",
    "print(f\"scikit-learn: {sklearn.__version__}\")\n",
    "print(f\"xgboost: {xgboost.__version__}\")\n",
    "print(f\"matplotlib: {matplotlib.__version__}\")\n",
    "print(f\"seaborn: {sns.__version__}\")\n",
    "print(f\"plotly: {plotly.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51a482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "script_path = r'C:\\Users\\KIIT\\OneDrive\\Desktop\\mini_project\\Mini_project.py'\n",
    "print(f\"File exists: {os.path.exists(script_path)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "80adf9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting stock prediction pipeline...\n",
      "\n",
      "System Stats - CPU: 24.3% | RAM: 61.8% (Used: 9.6GB/15.6GB)\n",
      "\n",
      "Loading data...\n",
      "Memory usage reduced from 0.05 MB to 0.03 MB (42.8% reduction)\n",
      "Memory usage reduced from 0.05 MB to 0.02 MB (57.0% reduction)\n",
      "Memory usage reduced from 0.05 MB to 0.02 MB (60.6% reduction)\n",
      "Data loaded in 0.03 seconds\n",
      "Train shape: (1000, 4), Test shape: (1000, 4), Validation shape: (1000, 4)\n",
      "\n",
      "Preprocessing data...\n",
      "Data preprocessed in 0.00 seconds\n",
      "\n",
      "Training Linear Regression...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b8a16c465564355aec0310d17da30af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Linear Regression:   0%|          | 0/100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.01 seconds\n",
      "\n",
      "System Stats - CPU: 46.9% | RAM: 61.8% (Used: 9.6GB/15.6GB)\n",
      "\n",
      "Making predictions with Linear Regression...\n",
      "Generating plots for Linear Regression...\n",
      "  - train set plot saved: Linear_Regression_train_performance.png\n",
      "  - test set plot saved: Linear_Regression_test_performance.png\n",
      "  - val set plot saved: Linear_Regression_val_performance.png\n",
      "Completed Linear Regression\n",
      "==================================================\n",
      "\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2bff41b4bd4f0798405e7dd48a6cc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Random Forest:   0%|          | 0/100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.17 seconds\n",
      "\n",
      "System Stats - CPU: 28.5% | RAM: 48.9% (Used: 7.6GB/15.6GB)\n",
      "\n",
      "Making predictions with Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks      | elapsed:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating plots for Random Forest...\n",
      "  - train set plot saved: Random_Forest_train_performance.png\n",
      "  - test set plot saved: Random_Forest_test_performance.png\n",
      "  - val set plot saved: Random_Forest_val_performance.png\n",
      "Completed Random Forest\n",
      "==================================================\n",
      "\n",
      "Training Support Vector Regressor...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9db9d98eae411b9b66ff2b8c50bb8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Support Vector Regressor:   0%|          | 0/100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.06 seconds\n",
      "\n",
      "System Stats - CPU: 22.8% | RAM: 51.2% (Used: 8.0GB/15.6GB)\n",
      "\n",
      "Making predictions with Support Vector Regressor...\n",
      "Generating plots for Support Vector Regressor...\n",
      "  - train set plot saved: Support_Vector_Regressor_train_performance.png\n",
      "  - test set plot saved: Support_Vector_Regressor_test_performance.png\n",
      "  - val set plot saved: Support_Vector_Regressor_val_performance.png\n",
      "Completed Support Vector Regressor\n",
      "==================================================\n",
      "\n",
      "Training XGBoost...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed1dc1486d1a4bfca13ad5d4a558c769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training XGBoost:   0%|          | 0/100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed in 0.04 seconds\n",
      "\n",
      "System Stats - CPU: 25.0% | RAM: 54.5% (Used: 8.5GB/15.6GB)\n",
      "\n",
      "Making predictions with XGBoost...\n",
      "Generating plots for XGBoost...\n",
      "  - train set plot saved: XGBoost_train_performance.png\n",
      "  - test set plot saved: XGBoost_test_performance.png\n",
      "  - val set plot saved: XGBoost_val_performance.png\n",
      "Completed XGBoost\n",
      "==================================================\n",
      "\n",
      "Training Neural Network...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67dc92697cba4848a5157f30bba41b28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Neural Network:   0%|          | 0/100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 29477116.00000000\n",
      "Iteration 2, loss = 29476592.00000000\n",
      "Iteration 3, loss = 29476496.00000000\n",
      "Iteration 4, loss = 29475966.00000000\n",
      "Iteration 5, loss = 29475678.00000000\n",
      "Iteration 6, loss = 29475514.00000000\n",
      "Iteration 7, loss = 29475110.00000000\n",
      "Iteration 8, loss = 29474504.00000000\n",
      "Iteration 9, loss = 29474338.00000000\n",
      "Iteration 10, loss = 29473984.00000000\n",
      "Iteration 11, loss = 29473456.00000000\n",
      "Iteration 12, loss = 29473076.00000000\n",
      "Iteration 13, loss = 29472398.00000000\n",
      "Iteration 14, loss = 29471876.00000000\n",
      "Iteration 15, loss = 29471548.00000000\n",
      "Iteration 16, loss = 29470914.00000000\n",
      "Iteration 17, loss = 29470148.00000000\n",
      "Iteration 18, loss = 29469588.00000000\n",
      "Iteration 19, loss = 29468194.00000000\n",
      "Iteration 20, loss = 29467084.00000000\n",
      "Iteration 21, loss = 29466526.00000000\n",
      "Iteration 22, loss = 29464314.00000000\n",
      "Iteration 23, loss = 29463506.00000000\n",
      "Iteration 24, loss = 29461832.00000000\n",
      "Iteration 25, loss = 29461136.00000000\n",
      "Iteration 26, loss = 29459332.00000000\n",
      "Iteration 27, loss = 29456634.00000000\n",
      "Iteration 28, loss = 29455856.00000000\n",
      "Iteration 29, loss = 29453366.00000000\n",
      "Iteration 30, loss = 29451200.00000000\n",
      "Iteration 31, loss = 29449182.00000000\n",
      "Iteration 32, loss = 29446110.00000000\n",
      "Iteration 33, loss = 29443342.00000000\n",
      "Iteration 34, loss = 29440004.00000000\n",
      "Iteration 35, loss = 29438004.00000000\n",
      "Iteration 36, loss = 29434886.00000000\n",
      "Iteration 37, loss = 29431114.00000000\n",
      "Iteration 38, loss = 29426514.00000000\n",
      "Iteration 39, loss = 29422692.00000000\n",
      "Iteration 40, loss = 29418104.00000000\n",
      "Iteration 41, loss = 29414518.00000000\n",
      "Iteration 42, loss = 29407736.00000000\n",
      "Iteration 43, loss = 29406618.00000000\n",
      "Iteration 44, loss = 29397428.00000000\n",
      "Iteration 45, loss = 29394896.00000000\n",
      "Iteration 46, loss = 29389438.00000000\n",
      "Iteration 47, loss = 29379278.00000000\n",
      "Iteration 48, loss = 29371812.00000000\n",
      "Iteration 49, loss = 29365762.00000000\n",
      "Iteration 50, loss = 29359006.00000000\n",
      "Iteration 51, loss = 29353048.00000000\n",
      "Iteration 52, loss = 29339230.00000000\n",
      "Iteration 53, loss = 29330836.00000000\n",
      "Iteration 54, loss = 29325004.00000000\n",
      "Iteration 55, loss = 29314484.00000000\n",
      "Iteration 56, loss = 29301044.00000000\n",
      "Iteration 57, loss = 29293150.00000000\n",
      "Iteration 58, loss = 29285986.00000000\n",
      "Iteration 59, loss = 29273574.00000000\n",
      "Iteration 60, loss = 29259716.00000000\n",
      "Iteration 61, loss = 29248276.00000000\n",
      "Iteration 62, loss = 29238398.00000000\n",
      "Iteration 63, loss = 29219498.00000000\n",
      "Iteration 64, loss = 29211558.00000000\n",
      "Iteration 65, loss = 29191544.00000000\n",
      "Iteration 66, loss = 29183460.00000000\n",
      "Iteration 67, loss = 29170684.00000000\n",
      "Iteration 68, loss = 29150200.00000000\n",
      "Iteration 69, loss = 29137932.00000000\n",
      "Iteration 70, loss = 29127244.00000000\n",
      "Iteration 71, loss = 29104214.00000000\n",
      "Iteration 72, loss = 29083858.00000000\n",
      "Iteration 73, loss = 29076500.00000000\n",
      "Iteration 74, loss = 29053726.00000000\n",
      "Iteration 75, loss = 29041034.00000000\n",
      "Iteration 76, loss = 29008224.00000000\n",
      "Iteration 77, loss = 28993304.00000000\n",
      "Iteration 78, loss = 28983660.00000000\n",
      "Iteration 79, loss = 28946388.00000000\n",
      "Iteration 80, loss = 28930064.00000000\n",
      "Iteration 81, loss = 28905224.00000000\n",
      "Iteration 82, loss = 28894410.00000000\n",
      "Iteration 83, loss = 28861074.00000000\n",
      "Iteration 84, loss = 28849538.00000000\n",
      "Iteration 85, loss = 28813924.00000000\n",
      "Iteration 86, loss = 28789322.00000000\n",
      "Iteration 87, loss = 28768118.00000000\n",
      "Iteration 88, loss = 28745198.00000000\n",
      "Iteration 89, loss = 28705658.00000000\n",
      "Iteration 90, loss = 28689032.00000000\n",
      "Iteration 91, loss = 28652678.00000000\n",
      "Iteration 92, loss = 28635108.00000000\n",
      "Iteration 93, loss = 28600878.00000000\n",
      "Iteration 94, loss = 28567518.00000000\n",
      "Iteration 95, loss = 28553732.00000000\n",
      "Iteration 96, loss = 28513544.00000000\n",
      "Iteration 97, loss = 28481486.00000000\n",
      "Iteration 98, loss = 28454884.00000000\n",
      "Iteration 99, loss = 28415528.00000000\n",
      "Iteration 100, loss = 28378488.00000000\n",
      "Iteration 101, loss = 28357614.00000000\n",
      "Iteration 102, loss = 28302368.00000000\n",
      "Iteration 103, loss = 28282476.00000000\n",
      "Iteration 104, loss = 28237080.00000000\n",
      "Iteration 105, loss = 28215246.00000000\n",
      "Iteration 106, loss = 28170746.00000000\n",
      "Iteration 107, loss = 28146076.00000000\n",
      "Iteration 108, loss = 28098440.00000000\n",
      "Iteration 109, loss = 28055388.00000000\n",
      "Iteration 110, loss = 28018404.00000000\n",
      "Iteration 111, loss = 27979516.00000000\n",
      "Iteration 112, loss = 27934644.00000000\n",
      "Iteration 113, loss = 27901804.00000000\n",
      "Iteration 114, loss = 27881162.00000000\n",
      "Iteration 115, loss = 27830358.00000000\n",
      "Iteration 116, loss = 27770992.00000000\n",
      "Iteration 117, loss = 27729302.00000000\n",
      "Iteration 118, loss = 27686770.00000000\n",
      "Iteration 119, loss = 27649910.00000000\n",
      "Iteration 120, loss = 27584188.00000000\n",
      "Iteration 121, loss = 27564584.00000000\n",
      "Iteration 122, loss = 27506888.00000000\n",
      "Iteration 123, loss = 27474988.00000000\n",
      "Iteration 124, loss = 27407672.00000000\n",
      "Iteration 125, loss = 27361742.00000000\n",
      "Iteration 126, loss = 27329714.00000000\n",
      "Iteration 127, loss = 27276092.00000000\n",
      "Iteration 128, loss = 27196450.00000000\n",
      "Iteration 129, loss = 27167912.00000000\n",
      "Iteration 130, loss = 27117080.00000000\n",
      "Iteration 131, loss = 27072320.00000000\n",
      "Iteration 132, loss = 26995218.00000000\n",
      "Iteration 133, loss = 26955442.00000000\n",
      "Iteration 134, loss = 26895756.00000000\n",
      "Iteration 135, loss = 26852990.00000000\n",
      "Iteration 136, loss = 26796418.00000000\n",
      "Iteration 137, loss = 26732784.00000000\n",
      "Iteration 138, loss = 26687008.00000000\n",
      "Iteration 139, loss = 26628788.00000000\n",
      "Iteration 140, loss = 26561858.00000000\n",
      "Iteration 141, loss = 26546492.00000000\n",
      "Iteration 142, loss = 26473366.00000000\n",
      "Iteration 143, loss = 26396602.00000000\n",
      "Iteration 144, loss = 26319752.00000000\n",
      "Iteration 145, loss = 26257294.00000000\n",
      "Iteration 146, loss = 26241614.00000000\n",
      "Iteration 147, loss = 26157304.00000000\n",
      "Iteration 148, loss = 26074608.00000000\n",
      "Iteration 149, loss = 26025680.00000000\n",
      "Iteration 150, loss = 25953426.00000000\n",
      "Iteration 151, loss = 25911864.00000000\n",
      "Iteration 152, loss = 25841632.00000000\n",
      "Iteration 153, loss = 25753002.00000000\n",
      "Iteration 154, loss = 25722982.00000000\n",
      "Iteration 155, loss = 25618456.00000000\n",
      "Iteration 156, loss = 25588172.00000000\n",
      "Iteration 157, loss = 25474238.00000000\n",
      "Iteration 158, loss = 25414664.00000000\n",
      "Iteration 159, loss = 25351336.00000000\n",
      "Iteration 160, loss = 25332440.00000000\n",
      "Iteration 161, loss = 25210544.00000000\n",
      "Iteration 162, loss = 25166026.00000000\n",
      "Iteration 163, loss = 25066070.00000000\n",
      "Iteration 164, loss = 25007512.00000000\n",
      "Iteration 165, loss = 24957988.00000000\n",
      "Iteration 166, loss = 24875158.00000000\n",
      "Iteration 167, loss = 24762554.00000000\n",
      "Iteration 168, loss = 24687632.00000000\n",
      "Iteration 169, loss = 24643110.00000000\n",
      "Iteration 170, loss = 24542280.00000000\n",
      "Iteration 171, loss = 24522324.00000000\n",
      "Iteration 172, loss = 24403656.00000000\n",
      "Iteration 173, loss = 24306542.00000000\n",
      "Iteration 174, loss = 24259120.00000000\n",
      "Iteration 175, loss = 24153598.00000000\n",
      "Iteration 176, loss = 24117840.00000000\n",
      "Iteration 177, loss = 24041286.00000000\n",
      "Iteration 178, loss = 23950440.00000000\n",
      "Iteration 179, loss = 23837526.00000000\n",
      "Iteration 180, loss = 23751420.00000000\n",
      "Iteration 181, loss = 23676220.00000000\n",
      "Iteration 182, loss = 23623632.00000000\n",
      "Iteration 183, loss = 23507518.00000000\n",
      "Iteration 184, loss = 23418368.00000000\n",
      "Iteration 185, loss = 23366792.00000000\n",
      "Iteration 186, loss = 23251288.00000000\n",
      "Iteration 187, loss = 23184188.00000000\n",
      "Iteration 188, loss = 23111674.00000000\n",
      "Iteration 189, loss = 23005832.00000000\n",
      "Iteration 190, loss = 22948982.00000000\n",
      "Iteration 191, loss = 22864362.00000000\n",
      "Iteration 192, loss = 22728846.00000000\n",
      "Iteration 193, loss = 22648122.00000000\n",
      "Iteration 194, loss = 22564390.00000000\n",
      "Iteration 195, loss = 22477920.00000000\n",
      "Iteration 196, loss = 22376416.00000000\n",
      "Iteration 197, loss = 22355278.00000000\n",
      "Iteration 198, loss = 22188154.00000000\n",
      "Iteration 199, loss = 22118846.00000000\n",
      "Iteration 200, loss = 22073912.00000000\n",
      "Training completed in 0.51 seconds\n",
      "\n",
      "System Stats - CPU: 28.3% | RAM: 58.6% (Used: 9.1GB/15.6GB)\n",
      "\n",
      "Making predictions with Neural Network...\n",
      "Generating plots for Neural Network...\n",
      "  - train set plot saved: Neural_Network_train_performance.png\n",
      "  - test set plot saved: Neural_Network_test_performance.png\n",
      "  - val set plot saved: Neural_Network_val_performance.png\n",
      "Completed Neural Network\n",
      "==================================================\n",
      "\n",
      "Generating HTML report...\n",
      "HTML report generated in 0.00 seconds\n",
      "\n",
      "Best Performing Model: Linear Regression (Test R²: 0.9993)\n",
      "\n",
      "Final Report: stock_prediction_report_Close.html\n",
      "\n",
      "System Stats - CPU: 26.3% | RAM: 60.8% (Used: 9.5GB/15.6GB)\n"
     ]
    }
   ],
   "source": [
    "%run \"C:/Users/KIIT/OneDrive/Desktop/mini_project/Mini_project.py\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
